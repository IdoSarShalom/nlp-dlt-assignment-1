{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî• BiLSTM Model Training: Emotion Classification\n",
        "\n",
        "This notebook trains a Bidirectional LSTM model on preprocessed emotion data using **GloVe** pre-trained embeddings.\n",
        "\n",
        "**Embedding Strategy:** GloVe (Twitter, 200d) - captures global co-occurrence statistics that complement LSTM's long-term dependency learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Import Libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Install Dependencies (Run on Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if running on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Install dependencies only on Colab\n",
        "if IN_COLAB:\n",
        "    print(\"Running on Google Colab - Installing dependencies...\")\n",
        "    %pip install -q gensim==4.4.0 h5py==3.15.1 keras==3.12.0 matplotlib==3.10.6 nltk==3.9.2 numpy==2.2.5 pandas==2.3.3 scikit-learn==1.7.2 scipy==1.15.3 seaborn==0.13.2 tensorflow==2.20.0 wordcloud==1.9.4\n",
        "    print(\"Dependencies installed successfully!\")\n",
        "else:\n",
        "    print(\"Running locally - Using local dependencies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gensim.downloader as api\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÇ Load Preprocessed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (15999, 2)\n",
            "Validation data shape: (2000, 2)\n",
            "\n",
            "Columns: ['Text', 'Label']\n",
            "\n",
            "First few rows:\n",
            "                                                Text  Label\n",
            "0                              didnt feel humiliated      0\n",
            "1  go feeling hopeless damned hopeful around some...      0\n",
            "2          im grabbing minute post feel greedy wrong      3\n",
            "3  ever feeling nostalgic fireplace know still pr...      2\n",
            "4                                    feeling grouchy      3\n"
          ]
        }
      ],
      "source": [
        "# Load preprocessed training and validation data\n",
        "train_df = pd.read_pickle('./data/train_preprocessed.pkl')\n",
        "val_df = pd.read_pickle('./data/validation_preprocessed.pkl')\n",
        "\n",
        "print(f\"Training data shape: {train_df.shape}\")\n",
        "print(f\"Validation data shape: {val_df.shape}\")\n",
        "print(f\"\\nColumns: {train_df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(train_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Prepare Data\n",
        "\n",
        "Split the data into features (X) and labels (y).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 15999\n",
            "Validation samples: 2000\n",
            "\n",
            "Label distribution in training set:\n",
            "Label\n",
            "0    4666\n",
            "1    5361\n",
            "2    1304\n",
            "3    2159\n",
            "4    1937\n",
            "5     572\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Prepare X and y\n",
        "X_train = train_df['Text']\n",
        "y_train = train_df['Label']\n",
        "X_val = val_df['Text']\n",
        "y_val = val_df['Label']\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Validation samples: {len(X_val)}\")\n",
        "print(f\"\\nLabel distribution in training set:\")\n",
        "print(y_train.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî† Tokenization\n",
        "\n",
        "Convert text to sequences of integers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum sequence length: 35\n",
            "\n",
            "X_train_padded shape: (15999, 35)\n",
            "X_val_padded shape: (2000, 35)\n",
            "Vocabulary size (input_size): 15064\n"
          ]
        }
      ],
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer(num_words=60000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "# Find maximum sequence length\n",
        "maxlen = max(len(tokens) for tokens in X_train_sequences)\n",
        "print(f\"Maximum sequence length: {maxlen}\")\n",
        "\n",
        "# Pad sequences\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=maxlen, padding='post')\n",
        "X_val_padded = pad_sequences(X_val_sequences, maxlen=maxlen, padding='post')\n",
        "\n",
        "print(f\"\\nX_train_padded shape: {X_train_padded.shape}\")\n",
        "print(f\"X_val_padded shape: {X_val_padded.shape}\")\n",
        "\n",
        "# Calculate input size for embedding layer\n",
        "input_size = np.max(X_train_padded) + 1\n",
        "print(f\"Vocabulary size (input_size): {input_size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üåê Prepare GloVe Embeddings\n",
        "\n",
        "Using pre-trained **GloVe** embeddings for the LSTM model. GloVe captures global co-occurrence statistics, which complements LSTM's ability to learn long-term dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and prepare GloVe embeddings\n",
        "import gensim.downloader as api\n",
        "\n",
        "print(\"üì• Downloading GloVe pre-trained embeddings (Twitter 200d)...\")\n",
        "print(\"This may take a few minutes on first run...\")\n",
        "\n",
        "# Download pre-trained GloVe model (Twitter, 200 dimensions)\n",
        "# Using Twitter GloVe as it's trained on social media text (similar to emotions dataset)\n",
        "glove_model = api.load('glove-twitter-200')\n",
        "\n",
        "print(\"‚úÖ GloVe embeddings loaded successfully!\")\n",
        "\n",
        "# Embedding dimension\n",
        "embedding_dim = 200\n",
        "\n",
        "# Create embedding matrix\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "# Fill embedding matrix with GloVe vectors\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    try:\n",
        "        embedding_vector = glove_model[word]\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    except KeyError:\n",
        "        # Word not in GloVe vocabulary, leave as zeros\n",
        "        misses += 1\n",
        "\n",
        "print(f\"\\nüìä Embedding Matrix Statistics:\")\n",
        "print(f\"   Vocabulary size: {vocab_size}\")\n",
        "print(f\"   Embedding dimension: {embedding_dim}\")\n",
        "print(f\"   Words found in GloVe: {hits}\")\n",
        "print(f\"   Words not found (using zeros): {misses}\")\n",
        "print(f\"   Coverage: {100 * hits / (hits + misses):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî¨ Hyperparameter Tuning Experiments\n",
        "\n",
        "Now let's systematically test different hyperparameters to understand their impact on LSTM model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to create and train an LSTM model with custom hyperparameters\n",
        "def train_lstm_model(lstm_units=128, dropout_rate=0.5, learning_rate=0.001, \n",
        "                      batch_size=32, dense_units=64, epochs=10, \n",
        "                      embedding_trainable=False, optimizer_name='adam'):\n",
        "    \"\"\"\n",
        "    Train an LSTM model with specified hyperparameters and return validation results.\n",
        "    \"\"\"\n",
        "    # Build model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=maxlen,\n",
        "        trainable=embedding_trainable\n",
        "    ))\n",
        "    model.add(Bidirectional(LSTM(lstm_units)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(dense_units, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "    \n",
        "    # Compile with specified optimizer and learning rate\n",
        "    if optimizer_name == 'adam':\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    elif optimizer_name == 'rmsprop':\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    elif optimizer_name == 'sgd':\n",
        "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
        "    else:\n",
        "        optimizer = 'adam'\n",
        "    \n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='sparse_categorical_crossentropy', \n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        X_train_padded, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(X_val_padded, y_val),\n",
        "        callbacks=[EarlyStopping(patience=3, restore_best_weights=True)],\n",
        "        verbose=0  # Suppress output for cleaner results\n",
        "    )\n",
        "    \n",
        "    # Evaluate on validation set\n",
        "    val_loss, val_accuracy = model.evaluate(X_val_padded, y_val, verbose=0)\n",
        "    \n",
        "    return {\n",
        "        'val_accuracy': val_accuracy,\n",
        "        'val_loss': val_loss,\n",
        "        'best_epoch': len(history.history['val_accuracy']),\n",
        "        'history': history.history\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Helper function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîç Running All Hyperparameter Experiments\n",
        "\n",
        "Testing: Learning Rate, Batch Size, LSTM Units, Dropout Rate, Optimizer, and Embedding Trainability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Experiment 1: Learning Rate\n",
        "print(\"=\" * 80)\n",
        "print(\"EXPERIMENT 1: Learning Rate\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "learning_rates = [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
        "lr_results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"Testing learning rate: {lr}\")\n",
        "    result = train_lstm_model(learning_rate=lr, epochs=10)\n",
        "    lr_results.append({\n",
        "        'learning_rate': lr,\n",
        "        'val_accuracy': result['val_accuracy'],\n",
        "        'val_loss': result['val_loss']\n",
        "    })\n",
        "    print(f\"  Val Accuracy: {result['val_accuracy']:.4f}\\n\")\n",
        "\n",
        "lr_df = pd.DataFrame(lr_results)\n",
        "\n",
        "# Experiment 2: Batch Size\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXPERIMENT 2: Batch Size\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "batch_sizes = [16, 32, 64, 128]\n",
        "batch_results = []\n",
        "\n",
        "for bs in batch_sizes:\n",
        "    print(f\"Testing batch size: {bs}\")\n",
        "    result = train_lstm_model(batch_size=bs, epochs=10)\n",
        "    batch_results.append({\n",
        "        'batch_size': bs,\n",
        "        'val_accuracy': result['val_accuracy'],\n",
        "        'val_loss': result['val_loss']\n",
        "    })\n",
        "    print(f\"  Val Accuracy: {result['val_accuracy']:.4f}\\n\")\n",
        "\n",
        "batch_df = pd.DataFrame(batch_results)\n",
        "\n",
        "# Experiment 3: LSTM Units\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXPERIMENT 3: LSTM Units\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "lstm_units_list = [64, 96, 128, 192, 256]\n",
        "lstm_results = []\n",
        "\n",
        "for units in lstm_units_list:\n",
        "    print(f\"Testing LSTM units: {units}\")\n",
        "    result = train_lstm_model(lstm_units=units, epochs=10)\n",
        "    lstm_results.append({\n",
        "        'lstm_units': units,\n",
        "        'val_accuracy': result['val_accuracy'],\n",
        "        'val_loss': result['val_loss']\n",
        "    })\n",
        "    print(f\"  Val Accuracy: {result['val_accuracy']:.4f}\\n\")\n",
        "\n",
        "lstm_df = pd.DataFrame(lstm_results)\n",
        "\n",
        "# Experiment 4: Dropout Rate\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXPERIMENT 4: Dropout Rate\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "dropout_rates = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "dropout_results = []\n",
        "\n",
        "for dr in dropout_rates:\n",
        "    print(f\"Testing dropout rate: {dr}\")\n",
        "    result = train_lstm_model(dropout_rate=dr, epochs=10)\n",
        "    dropout_results.append({\n",
        "        'dropout_rate': dr,\n",
        "        'val_accuracy': result['val_accuracy'],\n",
        "        'val_loss': result['val_loss']\n",
        "    })\n",
        "    print(f\"  Val Accuracy: {result['val_accuracy']:.4f}\\n\")\n",
        "\n",
        "dropout_df = pd.DataFrame(dropout_results)\n",
        "\n",
        "# Experiment 5: Optimizer\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXPERIMENT 5: Optimizer\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "optimizers = ['adam', 'rmsprop', 'sgd']\n",
        "opt_results = []\n",
        "\n",
        "for opt in optimizers:\n",
        "    print(f\"Testing optimizer: {opt}\")\n",
        "    result = train_lstm_model(optimizer_name=opt, epochs=10)\n",
        "    opt_results.append({\n",
        "        'optimizer': opt,\n",
        "        'val_accuracy': result['val_accuracy'],\n",
        "        'val_loss': result['val_loss']\n",
        "    })\n",
        "    print(f\"  Val Accuracy: {result['val_accuracy']:.4f}\\n\")\n",
        "\n",
        "opt_df = pd.DataFrame(opt_results)\n",
        "\n",
        "# Experiment 6: Embedding Trainability\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXPERIMENT 6: Embedding Trainability\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "emb_configs = [False, True]\n",
        "emb_labels = ['Frozen', 'Fine-tuned']\n",
        "emb_results = []\n",
        "\n",
        "for trainable, label in zip(emb_configs, emb_labels):\n",
        "    print(f\"Testing: {label} embeddings\")\n",
        "    result = train_lstm_model(embedding_trainable=trainable, epochs=10)\n",
        "    emb_results.append({\n",
        "        'configuration': label,\n",
        "        'val_accuracy': result['val_accuracy'],\n",
        "        'val_loss': result['val_loss']\n",
        "    })\n",
        "    print(f\"  Val Accuracy: {result['val_accuracy']:.4f}\\n\")\n",
        "\n",
        "emb_df = pd.DataFrame(emb_results)\n",
        "\n",
        "print(\"\\n‚úÖ All experiments completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Comprehensive Hyperparameter Tuning Summary\n",
        "\n",
        "Visualize and compare all hyperparameter experiment results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualizations\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# Plot 1: Learning Rate\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.plot(lr_df['learning_rate'], lr_df['val_accuracy'], 'o-', linewidth=2, markersize=8, color='blue')\n",
        "ax1.set_xlabel('Learning Rate')\n",
        "ax1.set_ylabel('Val Accuracy')\n",
        "ax1.set_title('Learning Rate Impact')\n",
        "ax1.set_xscale('log')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "best_lr_idx = lr_df['val_accuracy'].idxmax()\n",
        "ax1.scatter(lr_df.loc[best_lr_idx, 'learning_rate'], lr_df.loc[best_lr_idx, 'val_accuracy'], \n",
        "           color='red', s=200, marker='*', zorder=5)\n",
        "\n",
        "# Plot 2: Batch Size\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.plot(batch_df['batch_size'], batch_df['val_accuracy'], 'o-', linewidth=2, markersize=8, color='green')\n",
        "ax2.set_xlabel('Batch Size')\n",
        "ax2.set_ylabel('Val Accuracy')\n",
        "ax2.set_title('Batch Size Impact')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "best_batch_idx = batch_df['val_accuracy'].idxmax()\n",
        "ax2.scatter(batch_df.loc[best_batch_idx, 'batch_size'], batch_df.loc[best_batch_idx, 'val_accuracy'], \n",
        "           color='red', s=200, marker='*', zorder=5)\n",
        "\n",
        "# Plot 3: LSTM Units\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "ax3.plot(lstm_df['lstm_units'], lstm_df['val_accuracy'], 'o-', linewidth=2, markersize=8, color='purple')\n",
        "ax3.set_xlabel('LSTM Units')\n",
        "ax3.set_ylabel('Val Accuracy')\n",
        "ax3.set_title('LSTM Units Impact')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "best_lstm_idx = lstm_df['val_accuracy'].idxmax()\n",
        "ax3.scatter(lstm_df.loc[best_lstm_idx, 'lstm_units'], lstm_df.loc[best_lstm_idx, 'val_accuracy'], \n",
        "           color='red', s=200, marker='*', zorder=5)\n",
        "\n",
        "# Plot 4: Dropout Rate\n",
        "ax4 = fig.add_subplot(gs[1, 0])\n",
        "ax4.plot(dropout_df['dropout_rate'], dropout_df['val_accuracy'], 'o-', linewidth=2, markersize=8, color='teal')\n",
        "ax4.set_xlabel('Dropout Rate')\n",
        "ax4.set_ylabel('Val Accuracy')\n",
        "ax4.set_title('Dropout Rate Impact')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "best_dropout_idx = dropout_df['val_accuracy'].idxmax()\n",
        "ax4.scatter(dropout_df.loc[best_dropout_idx, 'dropout_rate'], dropout_df.loc[best_dropout_idx, 'val_accuracy'], \n",
        "           color='red', s=200, marker='*', zorder=5)\n",
        "\n",
        "# Plot 5: Optimizer\n",
        "ax5 = fig.add_subplot(gs[1, 1])\n",
        "ax5.bar(opt_df['optimizer'], opt_df['val_accuracy'], color=['#3498db', '#2ecc71', '#e74c3c'], edgecolor='black', linewidth=2)\n",
        "ax5.set_xlabel('Optimizer')\n",
        "ax5.set_ylabel('Val Accuracy')\n",
        "ax5.set_title('Optimizer Impact')\n",
        "ax5.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Plot 6: Embedding Trainability\n",
        "ax6 = fig.add_subplot(gs[1, 2])\n",
        "ax6.bar(emb_df['configuration'], emb_df['val_accuracy'], color=['#9b59b6', '#1abc9c'], edgecolor='black', linewidth=2)\n",
        "ax6.set_xlabel('Embedding Mode')\n",
        "ax6.set_ylabel('Val Accuracy')\n",
        "ax6.set_title('Embedding Trainability Impact')\n",
        "ax6.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Create summary data\n",
        "summary_data = []\n",
        "summary_data.append({\n",
        "    'Hyperparameter': 'Learning Rate',\n",
        "    'Best Value': f\"{lr_df.loc[lr_df['val_accuracy'].idxmax(), 'learning_rate']}\",\n",
        "    'Val Accuracy': lr_df['val_accuracy'].max(),\n",
        "    'Val Loss': lr_df.loc[lr_df['val_accuracy'].idxmax(), 'val_loss']\n",
        "})\n",
        "summary_data.append({\n",
        "    'Hyperparameter': 'Batch Size',\n",
        "    'Best Value': f\"{int(batch_df.loc[batch_df['val_accuracy'].idxmax(), 'batch_size'])}\",\n",
        "    'Val Accuracy': batch_df['val_accuracy'].max(),\n",
        "    'Val Loss': batch_df.loc[batch_df['val_accuracy'].idxmax(), 'val_loss']\n",
        "})\n",
        "summary_data.append({\n",
        "    'Hyperparameter': 'LSTM Units',\n",
        "    'Best Value': f\"{int(lstm_df.loc[lstm_df['val_accuracy'].idxmax(), 'lstm_units'])}\",\n",
        "    'Val Accuracy': lstm_df['val_accuracy'].max(),\n",
        "    'Val Loss': lstm_df.loc[lstm_df['val_accuracy'].idxmax(), 'val_loss']\n",
        "})\n",
        "summary_data.append({\n",
        "    'Hyperparameter': 'Dropout Rate',\n",
        "    'Best Value': f\"{dropout_df.loc[dropout_df['val_accuracy'].idxmax(), 'dropout_rate']}\",\n",
        "    'Val Accuracy': dropout_df['val_accuracy'].max(),\n",
        "    'Val Loss': dropout_df.loc[dropout_df['val_accuracy'].idxmax(), 'val_loss']\n",
        "})\n",
        "summary_data.append({\n",
        "    'Hyperparameter': 'Optimizer',\n",
        "    'Best Value': opt_df.loc[opt_df['val_accuracy'].idxmax(), 'optimizer'],\n",
        "    'Val Accuracy': opt_df['val_accuracy'].max(),\n",
        "    'Val Loss': opt_df.loc[opt_df['val_accuracy'].idxmax(), 'val_loss']\n",
        "})\n",
        "summary_data.append({\n",
        "    'Hyperparameter': 'Embedding Mode',\n",
        "    'Best Value': emb_df.loc[emb_df['val_accuracy'].idxmax(), 'configuration'],\n",
        "    'Val Accuracy': emb_df['val_accuracy'].max(),\n",
        "    'Val Loss': emb_df.loc[emb_df['val_accuracy'].idxmax(), 'val_loss']\n",
        "})\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "# Plot 7: Summary Bar Chart (spanning bottom row)\n",
        "ax7 = fig.add_subplot(gs[2, :])\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(summary_df)))\n",
        "bars = ax7.barh(summary_df['Hyperparameter'], summary_df['Val Accuracy'], color=colors, edgecolor='black', linewidth=2)\n",
        "ax7.set_xlabel('Validation Accuracy', fontsize=12, fontweight='bold')\n",
        "ax7.set_title('Best Validation Accuracy for Each Hyperparameter', fontsize=14, fontweight='bold')\n",
        "ax7.grid(True, alpha=0.3, axis='x')\n",
        "for bar, val, best_val in zip(bars, summary_df['Val Accuracy'], summary_df['Best Value']):\n",
        "    ax7.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2, \n",
        "             f'{val:.4f} ({best_val})', va='center', fontweight='bold')\n",
        "\n",
        "plt.suptitle('LSTM Model - Hyperparameter Tuning Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.show()\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üèÜ HYPERPARAMETER TUNING RESULTS SUMMARY - LSTM MODEL\")\n",
        "print(\"=\" * 80)\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Print recommendations\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üí° RECOMMENDATIONS FOR OPTIMAL LSTM MODEL\")\n",
        "print(\"=\" * 80)\n",
        "for i, row in summary_df.iterrows():\n",
        "    print(f\"{row['Hyperparameter']:20s} {row['Best Value']}\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nüéØ Expected Validation Accuracy: {summary_df['Val Accuracy'].max():.4f}\")\n",
        "print(f\"üìâ Expected Validation Loss:     {summary_df['Val Loss'].min():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèÜ Extract Best Hyperparameters\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT:** Before running this cell, make sure you have run the **hyperparameter tuning experiment cell** above (Section: \"üîç Running All Hyperparameter Experiments\").\n",
        "\n",
        "This cell analyzes the comprehensive results to identify the best configuration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze all experimental results to find best hyperparameters\n",
        "print(\"üìä Summary of Best Hyperparameters from Experiments:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check if comprehensive_results_df exists\n",
        "if 'comprehensive_results_df' not in globals():\n",
        "    print(\"\\n‚ùå ERROR: Hyperparameter experiment results are missing!\")\n",
        "    print(\"Please run the hyperparameter tuning experiment cell first:\")\n",
        "    print(\"   - Section: 'üîç Running All Hyperparameter Experiments'\")\n",
        "    print(\"\\nThis cell tests all combinations of hyperparameters and creates\")\n",
        "    print(\"the comprehensive_results_df DataFrame with all results.\")\n",
        "    raise RuntimeError(\"Run hyperparameter experiments before extracting best configuration\")\n",
        "\n",
        "# Find best configuration from comprehensive results\n",
        "best_config = comprehensive_results_df.loc[comprehensive_results_df['val_accuracy'].idxmax()]\n",
        "\n",
        "print(f\"\\n‚úÖ Best Configuration:\")\n",
        "print(f\"   Learning Rate: {best_config['learning_rate']}\")\n",
        "print(f\"   Batch Size: {best_config['batch_size']:.0f}\")\n",
        "print(f\"   LSTM Units: {best_config['lstm_units']:.0f}\")\n",
        "print(f\"   Dropout Rate: {best_config['dropout_rate']}\")\n",
        "print(f\"   Dense Units: {best_config['dense_units']:.0f}\")\n",
        "print(f\"   Optimizer: {best_config['optimizer']}\")\n",
        "print(f\"   Embedding Trainable: {best_config['embedding_trainable']}\")\n",
        "print(f\"\\n   Validation Accuracy: {best_config['val_accuracy']:.4f}\")\n",
        "print(f\"   Validation Loss: {best_config['val_loss']:.4f}\")\n",
        "\n",
        "# Store best hyperparameters\n",
        "best_hyperparameters = {\n",
        "    'learning_rate': best_config['learning_rate'],\n",
        "    'batch_size': int(best_config['batch_size']),\n",
        "    'lstm_units': int(best_config['lstm_units']),\n",
        "    'dropout_rate': best_config['dropout_rate'],\n",
        "    'dense_units': int(best_config['dense_units']),\n",
        "    'optimizer': best_config['optimizer'],\n",
        "    'embedding_trainable': best_config['embedding_trainable']\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üéØ Final Best Configuration:\")\n",
        "print(\"=\" * 60)\n",
        "for key, value in best_hyperparameters.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Build Final BiLSTM Model with Best Hyperparameters\n",
        "\n",
        "Now we build the final model using the best hyperparameters identified from experiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build final model with best hyperparameters\n",
        "final_model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "final_model.add(Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=maxlen,\n",
        "    trainable=best_hyperparameters['embedding_trainable']\n",
        "))\n",
        "\n",
        "# Bidirectional LSTM layer with best units\n",
        "final_model.add(Bidirectional(LSTM(best_hyperparameters['lstm_units'])))\n",
        "\n",
        "# Batch normalization\n",
        "final_model.add(BatchNormalization())\n",
        "\n",
        "# Dropout with best rate\n",
        "final_model.add(Dropout(best_hyperparameters['dropout_rate']))\n",
        "\n",
        "# Dense layer with best units\n",
        "final_model.add(Dense(best_hyperparameters['dense_units'], activation='relu'))\n",
        "\n",
        "# Dropout\n",
        "final_model.add(Dropout(best_hyperparameters['dropout_rate']))\n",
        "\n",
        "# Output layer\n",
        "final_model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "# Compile with best optimizer and learning rate\n",
        "if best_hyperparameters['optimizer'] == 'adam':\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=best_hyperparameters['learning_rate'])\n",
        "elif best_hyperparameters['optimizer'] == 'rmsprop':\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=best_hyperparameters['learning_rate'])\n",
        "else:\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=best_hyperparameters['learning_rate'], momentum=0.9)\n",
        "\n",
        "final_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Build the model to initialize all layers\n",
        "final_model.build(input_shape=(None, maxlen))\n",
        "\n",
        "print(\"\\nüéØ Final BiLSTM Model with Best Hyperparameters\")\n",
        "print(f\"Learning Rate: {best_hyperparameters['learning_rate']}\")\n",
        "print(f\"Batch Size: {best_hyperparameters['batch_size']}\")\n",
        "print(f\"LSTM Units: {best_hyperparameters['lstm_units']}\")\n",
        "print(f\"Dropout Rate: {best_hyperparameters['dropout_rate']}\")\n",
        "print(f\"Dense Units: {best_hyperparameters['dense_units']}\")\n",
        "print(f\"Optimizer: {best_hyperparameters['optimizer']}\")\n",
        "print(f\"Embedding Trainable: {best_hyperparameters['embedding_trainable']}\")\n",
        "print()\n",
        "final_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Train Final Model\n",
        "\n",
        "Train the final model with the best hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the final model\n",
        "print(\"üöÄ Training final model with best hyperparameters...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Analyze epochs from experiments to set reasonable max_epochs\n",
        "avg_epochs = comprehensive_results_df['best_epoch'].mean()\n",
        "print(f\"Average epochs from experiments: {avg_epochs:.1f}\")\n",
        "print(f\"Setting max_epochs=30 with early stopping (patience=5)\")\n",
        "print(f\"This prevents overfitting while allowing enough training time.\\n\")\n",
        "\n",
        "# Early Stopping callback:\n",
        "# - Monitors validation loss (more stable than accuracy)\n",
        "# - patience=5: stops if no improvement for 5 epochs\n",
        "# - restore_best_weights=True: uses weights from best epoch\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = final_model.fit(\n",
        "    X_train_padded, y_train,\n",
        "    epochs=30,  # Max epochs (will likely stop earlier via EarlyStopping)\n",
        "    batch_size=best_hyperparameters['batch_size'],\n",
        "    validation_data=(X_val_padded, y_val),\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "actual_epochs = len(history.history['loss'])\n",
        "print(f\"\\n‚úÖ Training completed!\")\n",
        "print(f\"Trained for {actual_epochs} epochs (stopped early to prevent overfitting)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualize Training Progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot accuracy\n",
        "axes[0].plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
        "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
        "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot loss\n",
        "axes[1].plot(history.history['loss'], label='Training Loss', marker='o')\n",
        "axes[1].plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
        "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final metrics\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "\n",
        "print(f\"\\nüìä Final Training Metrics:\")\n",
        "print(f\"  Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"  Validation Accuracy: {final_val_acc:.4f}\")\n",
        "print(f\"  Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"  Validation Loss: {final_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Evaluate Final Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on validation set\n",
        "val_loss, val_accuracy = final_model.evaluate(X_val_padded, y_val, verbose=0)\n",
        "print(f\"\\nüìä Final Model Performance:\")\n",
        "print(f\"  Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = final_model.predict(X_val_padded, verbose=0)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_val, y_pred_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Sadness', 'Joy', 'Love', 'Anger', 'Fear', 'Surprise'],\n",
        "            yticklabels=['Sadness', 'Joy', 'Love', 'Anger', 'Fear', 'Surprise'])\n",
        "plt.title('Confusion Matrix - Final BiLSTM Model', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Classification Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate classification report\n",
        "emotion_labels = ['Sadness', 'Joy', 'Love', 'Anger', 'Fear', 'Surprise']\n",
        "report = classification_report(y_val, y_pred_classes, target_names=emotion_labels)\n",
        "print(\"\\nüìù Classification Report:\")\n",
        "print(\"=\" * 60)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ Save Final Model and Tokenizer\n",
        "\n",
        "Save the final model (trained with best hyperparameters), tokenizer, and metadata.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create output directory\n",
        "output_dir = './data/lstm'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save the final model\n",
        "model_path = os.path.join(output_dir, 'lstm_model.keras')\n",
        "final_model.save(model_path)\n",
        "print(f\"‚úÖ Model saved to: {model_path}\")\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer_path = os.path.join(output_dir, 'lstm_tokenizer.pkl')\n",
        "with open(tokenizer_path, 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "print(f\"‚úÖ Tokenizer saved to: {tokenizer_path}\")\n",
        "\n",
        "# Save metadata including best hyperparameters\n",
        "metadata = {\n",
        "    'maxlen': maxlen,\n",
        "    'vocab_size': vocab_size,\n",
        "    'embedding_dim': embedding_dim,\n",
        "    'best_hyperparameters': best_hyperparameters,\n",
        "    'val_accuracy': val_accuracy,\n",
        "    'val_loss': val_loss,\n",
        "    'emotion_labels': emotion_labels\n",
        "}\n",
        "\n",
        "metadata_path = os.path.join(output_dir, 'lstm_metadata.pkl')\n",
        "with open(metadata_path, 'wb') as f:\n",
        "    pickle.dump(metadata, f)\n",
        "print(f\"‚úÖ Metadata saved to: {metadata_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ All files saved successfully!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nFinal Model Performance:\")\n",
        "print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"  Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"\\nBest Hyperparameters Used:\")\n",
        "for key, value in best_hyperparameters.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp-emotions",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
